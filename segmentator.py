# -*- coding: utf-8 -*-
"""ultimate-guitar - сегменты

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tyQFPz7Q_hhaplZWNIgXtxsdziZcwfgD
"""

!pip install stop-words

import re
import nltk

nltk.download('punkt')
nltk.download('wordnet')

from nltk.stem import WordNetLemmatizer
from stop_words import get_stop_words
from nltk.util import ngrams
from itertools import chain
from collections import Counter

STOPWORDS_RU = get_stop_words('russian')
STOPWORDS_EN = get_stop_words('english')
STOPWORDS_OTHER = ["what", "the", "www", "how", "to", "on", "in", "with", "of", "a", "for"]

with open('stop_words.txt', 'r', encoding='utf-8') as _sw_file:
  content = _sw_file.read()
  STOPWORDS_OTHER.extend(content.split(","))

stop_words = chain(STOPWORDS_EN, STOPWORDS_RU, STOPWORDS_OTHER)

pattern = r'[\W^\s]'
pattern_2 = r'\s+'

lemmitizer = WordNetLemmatizer()

def clear_text(text):
  cleared_text = re.sub(pattern, " ", re.sub(pattern_2, ' ', text))
  cleared_text = re.sub(pattern_2, " ", cleared_text)
  return cleared_text

with open('data.txt', 'r', encoding='utf-8') as f:
  data = re.sub(r'==.*?==+', '', " ".join(f.readlines()).replace('\n', ' '))

  text = clear_text(data)
  #text_list = [lemmitizer.lemmatize(word) for word in text.split()]
  text_list = [lemmitizer.lemmatize(word) for word in text.split(" ") if word not in stop_words]
  #unigrams = Counter(text_list).most_common(100)
  bigrams = Counter(list(nltk.bigrams(text_list))).most_common(4000)
  trigrams = Counter(list(nltk.trigrams(text_list))).most_common(1000)
  #quatergrams = Counter(list(ngrams(text_list, 4))).most_common(100)

  with open('out.txt', 'w', encoding='utf-8') as out_f:
    new_d =  chain(bigrams, trigrams)
    for i in map(str, new_d):
      out_f.write(f"{i}\n")

